{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  TP  MCS  1 à 3  : Reconnaissance de commandes audio par DTW\n",
    "\n",
    "**Nom du Groupe :**\n",
    "\n",
    "**Noms :**\n",
    "\n",
    "**Prénoms :**\n",
    "\n",
    "**Parcours :**\n",
    "\n",
    "Ces trois séances de TP (2 séances encadrées et une non encadrée) vont vous permettre de tester l'algorithme de programmation dynamique vu en\n",
    "TD puis de réaliser la mise en oeuvre d'un système de reconnaissance audio de mots isolés (constituant des\n",
    "commandes pour les drones).\n",
    "\n",
    "\n",
    "\n",
    "Ces séances se décomposent en 3 parties : \n",
    "- Partie I : DTW et application du TD\n",
    "- Partie II : Système de reconnaissance audio de mots de commande\n",
    "- Partie III : Comparaison de la programmation dynamique avec une méthode de classification après prétraitement des données\n",
    "\n",
    "Pour les **parties II et III**, vous testerez le système de reconnaissance audio sur deux corpus de voix qui serviront respectivement de base d'apprentissage (références) et de base de test (sons à reconnaître) que vous choisirez. La liste des 13 commandes au drone sont : *Atterrissage, Décollage, Avance, Tourne droite, Recule, Tourne gauche, Droite, Fais un flip, Gauche, Arrête toi, plus haut, plus bas et Etat d'urgence.*\n",
    "\n",
    "\n",
    "\n",
    "Pour cela, vous devez par groupe de **3 étudiants** (effectif **OBLIGATOIRE**):\n",
    "1. **Proposer une étude** que vous détaillerez sur un rapport\n",
    "[par exemple, *influence voix masculines VS voix féminines, confronter vos propres voix à la base de données, tester l'impact de différents bruits de fond sur la reconnaissance...*];\n",
    "2. Créer, en fonction de l'objectif de votre étude, vos propres base d'apprentissage et base de test à partir du corpus proposé et des voix et bruits que vous aurez enregistrés [*paramètres audio : 16 KHz, mono, 16 bits, format *.wav**];\n",
    "3. Tester la DTW et une méthode de classification avec prétraitement par ACP;\n",
    "4. Evaluer les résultats; \n",
    "5. Rédiger un rapport en pdf présentant l'étude, les résultats par les 2 méthodes et vos commentaires et conclusions sur votre étude (Longueur max. : 5 pages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import array, zeros, full, argmin, inf, ndim\n",
    "import scipy\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie I : Implémentation de l'algorithme de programmation dynamique \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ecrivez une fonction en python DTW qui implémente le calcul et l'affichage de la matrice des coûts définie en TD. \n",
    "\n",
    "2. Afin d'adapter facilement le calcul des coûts suivant la nature des données (et donc des distances utilisées), écrivez une fonction pour chaque distance (euclidienne, lettres, sons) qui apparaîtra en paramètre de la fonction DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application aux exercices \n",
    "\n",
    "1. Testez vos programmes sur les exercices vus en TD. \n",
    "\n",
    "2. Modifiez les contraintes locales c'est-à-dire les pondérations suivant les directions. \n",
    "\n",
    "3. Ajoutez la prise en compte de contraintes globales c'est-à-dire le non calcul lorsque les cases sont trop éloignées de la diagonale (cf exercice TD séquence ADN). A partir de quelle position les contraintes globales ne changent pas les résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie II :  Système de reconnaissance audio de mots de commande\n",
    "\n",
    "Sur l'espace partagé, vous trouverez des enregistrements audio de mots de commandes pour un drone quadricoptère constitués de plusieurs locuteurs masculins (notés M01..M13) et locutrice féminines (F01..F05).\n",
    "\n",
    "Vous pouvez diviser ainsi l'ensemble des données en base d'apprentissage qui serviront de références et base de test pour évaluer la reconnaissance par programmation dynamique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les lignes de code suivantes permettent de transformer le fichier audio en matrice de paramètres appélés MFCC (Mel Frequency Cepstral Coefficient) en utilisant la librairie python *librosa*. Ces paramètres permettent d'extraire au mieux le contenu vocal fréquenciel de signal audio.\n",
    "\n",
    "La matrice de sortie est composée d'autant de vecteurs colonnes que de trames d'analyses. Le nombre de lignes correspond à la dimension du vecteur représentatif : ici 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chargement d'un fichier audio :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"./M01_arretetoi.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcul des MFCC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb Coeff MFCC x Nb Fenetres : (12, 32)\n"
     ]
    }
   ],
   "source": [
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=1024, htk=True, n_mfcc=12)\n",
    "print(\"Nb Coeff MFCC x Nb Fenetres :\",mfcc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application de la DTW**\n",
    "\n",
    "1. Réaliser une étude que vous détaillerez sur un rapport (par exemple, *influence voix masculines VS voix féminines, confronter votre propre voix à la base de données, tester l'impact de différents bruits de fond sur la reconnaissance...*) et créer votre propre base d'apprentissage et votre base de test à partir du corpus et des voix et bruits que vous aurez enregistrés. \n",
    "\n",
    "2. Appliquer la DTW sur vos corpus.\n",
    "\n",
    "**Paramètres pour enregistrements audio de vos voix perso:**\n",
    "\n",
    "16 KHz, mono, 16 bits, format *.wav*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation de la reconnaissance**\n",
    "\n",
    "1. Calculer la matrice de confusion du système (en ligne les références et en colonne les sorties du système). \n",
    "Vous pourrez utiliser la fonction *confusion_matrix* de la librairie *sklearn*.\n",
    "\n",
    "\n",
    "2. Calculer le score de reconnaissance : nombre de fichiers bien reconnus sur nombre de fichiers testés. \n",
    "\n",
    "*Vérifications :*\n",
    "-  si vous prenez comme fichier de référence et de test M01, vous devez obtenir aucune erreur.\n",
    "-  si vous prenez comme fichier de reférénce M01 et fichier de test M02, vous devez obtenir deux erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie III : Comparaison de la programmation dynamique avec une méthode de classification après prétraitement des données\n",
    "\n",
    "Dans cette partie, nous allons comparer les résultats de la DTW avec ceux d'une méthode de classification de données : les k-plus proches voisins.\n",
    "\n",
    "Nous utiliserons les fonctions permettant de calculer l'ACP et les k-ppv via la librairie python *scikit-learn*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement par ACP\n",
    "\n",
    "Pour tester une méthode de classification, il faut d'abord réduire la dimension des MFCC\n",
    "\n",
    "1. A partir de tous les enregistrements de la base d'apprentissage, réalisez une Analyse en composantes principales (A.C.P) en utilisant la fonction *PCA* de la librairie *scikit-learn* puis projetez les données de test dans cette nouvelle base. \n",
    "\n",
    "*Remarque :* vous pouvez aussi implémenter l'ACP en\n",
    "extrayant les 3 vecteurs propres, notés $X_1$, $X_2$, $X_3$, associés aux 3 plus grandes valeurs propres de la matrice de\n",
    "variance-covariance $\\Sigma_{App}$ (par les fonctions *np.cov* et *np.linalg.eig*). Ces vecteurs propres constitueront le nouveau repère $P$.  Projetez ensuite les données de la base d'apprentissage et de test dans cette nouvelle base en multipliant chaque vecteur par la base $P = [X_1X_2X_3]$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification par $k$ plus proches voisins\n",
    "\n",
    "En intelligence artificielle, la méthode des $k$ plus proches voisins (k-ppv) est une méthode d'apprentissage\n",
    "supervisé. Dans ce cadre, on dispose d'une base de données d'apprentissage constituée de couples  \"donnée-label\". Pour estimer la sortie associée à une nouvelle entrée $x$, la méthode des $k$ plus proches voisins consiste à prendre\n",
    "en compte (de façon identique) les $k$ échantillons d'apprentissage dont l'entrée est la plus proche de la nouvelle\n",
    "entrée $x$, selon une distance à définir. L'algorithme 1 associé et un exemple sont donnés par la suite.\n",
    "\n",
    "<img src=\"files/AlgoKppv.png\" width=\"900\" height=\"800\"  >\n",
    "\n",
    "<img src=\"files/kppv.png\" width=\"300\" height=\"300\"  >\n",
    "\n",
    "**Exemple de classification par $k$-ppv.** L'échantillon de test (cercle vert) doit être classé soit dans la première\n",
    "classe des carrés bleus, soit dans la deuxième classe des triangles rouges. \n",
    "Si $k = 3$ (cercle plein), il est assigné à la deuxième classe parce qu'il y a 2 triangles et seulement 1 carré à l'intérieur du cercle intérieur. \n",
    "Si $k = 5$ (cercle en pointillés), il est assigné à la première classe (3 carrés contre 2 triangles à l'intérieur du cercle extérieur)\n",
    "\n",
    "\n",
    "1. En utilisant la fonction *KNeighborsClassifier* de la librairie *sklearn.neighbors*, réalisez une classification par k-ppv sur la base d'apprentissage et la base de test que vous avez prédéfinies (prendre $k=1$).\n",
    "\n",
    "2. Evaluez la méthode des k-ppv par le calcul de la matrice de confusion et du taux de reconnaissance.\n",
    "\n",
    "3. Modifiez la valeur de $k$ pour les k-ppv. Améliorez-vous les scores de reconnaissance ?\n",
    "\n",
    "4. Comparez vos résultats avec ceux de la DTW.\n",
    "\n",
    "5. Rédigez un rapport sur votre étude, vos résultats et vos commentaires/conclusions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
